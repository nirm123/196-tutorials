{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aslModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(aslModel, self).__init__()\n",
    "        # (w - k + 2p)/s + 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, 6, 1) # (200 - 6)/1 + 1 = 195\n",
    "        self.conv2 = nn.Conv2d(32, 64, 6, 1) # (195 - 6)/1 + 1 = 190\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2) # (190)/2 = 95\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 6, 1) # (95 - 6)/1 + 1 = 90\n",
    "        self.conv4 = nn.Conv2d(128, 256, 5, 1) # (90 - 5)/1 + 1 = 86\n",
    "\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "        # 43\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 256, 11, 1) # (43 - 11)/1 + 1 = 33\n",
    "        self.conv6 = nn.Conv2d(256, 256, 14, 1) # (33 - 14)/1 + 1 = 20\n",
    "        # 20\n",
    "        \n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.drop4 = nn.Dropout(0.5)\n",
    "        self.drop5 = nn.Dropout(0.5)\n",
    "\n",
    "        self.full1 = nn.Linear(256 * 10 * 10, 128)\n",
    "        self.full2 = nn.Linear(128, 128)\n",
    "        self.full3 = nn.Linear(128, 36)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.pool(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
    "        x = self.drop2(self.pool(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
    "        x = self.drop3(self.pool(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
    "\n",
    "        x = x.view(-1, 256 * 10 * 10)\n",
    "        x = self.drop4(F.relu(self.full1(x)))\n",
    "        x = self.drop5(F.relu(self.full2(x)))\n",
    "        x = self.full3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "massey_dataset = datasets.ImageFolder(root='massey',\n",
    "                                           transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(massey_dataset,\n",
    "                                             batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aslModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "loss = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 28, 15,  7, 21,  7,  7,  7, 28,  7])\n",
      "tensor([35, 22, 35,  4,  6,  0,  2, 28, 19, 35])\n",
      "0.0\n",
      "tensor([26, 26,  0,  0, 19,  0, 28,  0,  0,  0])\n",
      "tensor([16,  0,  9,  6, 17,  3, 16,  9, 30, 10])\n",
      "0.0\n",
      "tensor([28, 32,  9, 21, 28,  6,  7, 28, 34, 15])\n",
      "tensor([ 0, 11, 19, 15,  3, 31, 27, 14, 32, 18])\n",
      "0.0\n",
      "tensor([ 9,  9, 27, 28,  9, 27,  2,  9, 20,  9])\n",
      "tensor([20,  8, 16, 17,  9, 21,  1,  7, 22, 12])\n",
      "0.1\n",
      "tensor([16,  9, 16, 19, 33, 16, 34,  3, 22,  4])\n",
      "tensor([13,  7, 35, 14, 16, 15, 28,  1, 12,  0])\n",
      "0.0\n",
      "tensor([35, 35, 11,  6, 15,  9, 27,  2, 35, 22])\n",
      "tensor([33, 15, 31, 28, 30, 28, 14, 17, 10,  9])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([29, 31,  6, 35,  1,  9,  2,  3, 26, 29])\n",
      "0.1\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([ 8, 18, 17, 11, 28, 30, 28, 22,  0, 15])\n",
      "0.0\n",
      "tensor([14,  9, 35, 13, 16,  9, 16, 17, 16, 35])\n",
      "tensor([10,  5, 12, 14, 10,  8,  9, 32, 35,  4])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([ 0,  7, 24, 17,  4, 32, 19, 25,  0, 26])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 28])\n",
      "tensor([26, 30, 21, 11,  5, 14, 16,  5,  1, 35])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([ 0, 32,  0, 21, 19, 21, 18, 30, 14, 25])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([ 1, 23, 26,  6,  6, 33,  9,  9, 23, 18])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 30, 35, 35, 35])\n",
      "tensor([ 5,  7,  7,  7, 29,  3, 13, 16, 15, 12])\n",
      "0.0\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35])\n",
      "tensor([28, 24,  6, 28, 14, 16, 34, 29, 25, 13])\n",
      "0.0\n",
      "tensor([17, 10, 10, 10,  9,  9, 30, 35, 17,  9])\n",
      "tensor([ 2, 24, 34, 29,  3,  5, 25, 34, 33,  1])\n",
      "0.0\n",
      "tensor([17,  6, 35,  9, 30, 35, 17,  9,  9, 17])\n",
      "tensor([ 3, 19, 30,  9,  1,  1,  6,  9, 20, 33])\n",
      "0.2\n",
      "tensor([17,  9,  9,  9,  9, 17, 28,  9, 16, 17])\n",
      "tensor([34, 14, 13, 25,  8, 20, 24,  1, 29, 14])\n",
      "0.0\n",
      "tensor([17, 30,  9, 17, 17,  9, 14, 35, 30, 30])\n",
      "tensor([23, 24, 31, 16, 19, 13, 27, 26, 11, 13])\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d53b30d15fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcurr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (X_train_batch, Y_train_batch) in enumerate(dataset_loader):\n",
    "        if(Y_train_batch.shape[0]<batch):\n",
    "            continue\n",
    "            \n",
    "        output = model(X_train_batch)\n",
    "        curr_loss = criterion(output, Y_train_batch)\n",
    "        loss.append(curr_loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        curr_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct = (predicted == Y_train_batch).sum().item()\n",
    "        accuracy.append(correct/Y_train_batch.size(0))\n",
    "        print(predicted)\n",
    "        print(Y_train_batch)\n",
    "        print(accuracy[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
