{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 + Transfer Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "This will be a simple application of transfer learning for CIFAR10. We are using a pretrained ResNet-18 model.\n",
    "\n",
    "Next, we can finally start working on our project. These are the two papers I found, but you can look for more.\n",
    "\n",
    "1. [Real-time American Sign Language Recognition with Convolutional Neural\n",
    "Networks](http://cs231n.stanford.edu/reports/2016/pdfs/214_Report.pdf)\n",
    "2. [Using Deep Convolutional Networks for\n",
    "Gesture Recognition in American Sign Language](https://arxiv.org/pdf/1710.06836.pdf)\n",
    "\n",
    "There are also two datasets that we can work with. Part of the group might want to research setting up a dataloader with this dataset in pytorch.\n",
    "\n",
    "1. [ASL Finger Spelling Dataset](https://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset)\n",
    "2. [Massey University Gesture Dataset](https://www.massey.ac.nz/~albarcza/gesture_dataset2012.html)\n",
    "\n",
    "## Resources\n",
    "\n",
    "Really good notes if you want to get a better understanding of the topics (http://cs231n.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for building network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Libraries for dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Miscellaneous Libraries\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs for training\n",
    "num_epochs = 1\n",
    "\n",
    "# Batch Size for training/testing\n",
    "batch_size = 10\n",
    "\n",
    "# Learning Rate for optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Dimensions of model (ResNet-18)\n",
    "dim = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for training data\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    transforms.RandomResizedCrop(dim),\n",
    "    transforms.ToTensor(),                            # Convert grayscale image to pytorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),             # Normalize grayscale data\n",
    "])\n",
    "\n",
    "# Transformation for training data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),                            # Convert grayscale image to pytorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),             # Normalize grayscale data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download training data\n",
    "trainset = torchvision.datasets.CIFAR10(root='./files', train=True, download=True, \n",
    "                                      transform=transform_train)\n",
    "\n",
    "# Initialize dataloader for training data\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                                           num_workers=8)\n",
    "\n",
    "# Download testing Data\n",
    "testset = torchvision.datasets.CIFAR10(root='./files', train=False, download=False, \n",
    "                                     transform=transform_test)\n",
    "\n",
    "# Initialize dataloader for testing data\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, \n",
    "                                          num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model/Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/nirmal/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Initialize pretrained ResNet-18 model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Turn of gradient calculation for all layers (We don't train them)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create new final fully-connected layer for our problem\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)                                             \n",
    "\n",
    "# Definie loss function (Cross Entropy Loss)\n",
    "criterion = nn.CrossEntropyLoss()                                      \n",
    "\n",
    "# Initialize Optimizer (ADAM)\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=learning_rate)     \n",
    "\n",
    "# Set model to training (updating weights)\n",
    "model.train();                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Step: 1/5000, Loss: 2.339088201522827, Accuracy: 50.0%\n",
      "Epoch: 1/1, Step: 101/5000, Loss: 0.2584473490715027, Accuracy: 90.0%\n",
      "Epoch: 1/1, Step: 201/5000, Loss: 1.5821659564971924, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 301/5000, Loss: 1.8110291957855225, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 401/5000, Loss: 1.1028445959091187, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 501/5000, Loss: 3.5460333824157715, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 601/5000, Loss: 2.0474369525909424, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 701/5000, Loss: 3.0690550804138184, Accuracy: 50.0%\n",
      "Epoch: 1/1, Step: 801/5000, Loss: 1.1711140871047974, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 901/5000, Loss: 3.6495842933654785, Accuracy: 50.0%\n",
      "Epoch: 1/1, Step: 1001/5000, Loss: 2.691936492919922, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 1101/5000, Loss: 3.1493656635284424, Accuracy: 40.0%\n",
      "Epoch: 1/1, Step: 1201/5000, Loss: 0.8947970271110535, Accuracy: 80.0%\n",
      "Epoch: 1/1, Step: 1301/5000, Loss: 0.5981310606002808, Accuracy: 90.0%\n",
      "Epoch: 1/1, Step: 1401/5000, Loss: 2.2464940547943115, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 1501/5000, Loss: 3.5405235290527344, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 1601/5000, Loss: 1.220516562461853, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 1701/5000, Loss: 1.9257538318634033, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 1801/5000, Loss: 5.733102798461914, Accuracy: 20.0%\n",
      "Epoch: 1/1, Step: 1901/5000, Loss: 0.9223728179931641, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 2001/5000, Loss: 1.4788490533828735, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 2101/5000, Loss: 2.848007917404175, Accuracy: 40.0%\n",
      "Epoch: 1/1, Step: 2201/5000, Loss: 4.9136762619018555, Accuracy: 30.0%\n",
      "Epoch: 1/1, Step: 2301/5000, Loss: 0.7194931507110596, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 2401/5000, Loss: 0.8110743761062622, Accuracy: 80.0%\n",
      "Epoch: 1/1, Step: 2501/5000, Loss: 2.7244763374328613, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 2601/5000, Loss: 1.7225100994110107, Accuracy: 50.0%\n",
      "Epoch: 1/1, Step: 2701/5000, Loss: 2.6489572525024414, Accuracy: 30.0%\n",
      "Epoch: 1/1, Step: 2801/5000, Loss: 3.728403091430664, Accuracy: 40.0%\n",
      "Epoch: 1/1, Step: 2901/5000, Loss: 3.200944423675537, Accuracy: 50.0%\n",
      "Epoch: 1/1, Step: 3001/5000, Loss: 3.1108176708221436, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 3101/5000, Loss: 0.9580085873603821, Accuracy: 90.0%\n",
      "Epoch: 1/1, Step: 3201/5000, Loss: 2.1034979820251465, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 3301/5000, Loss: 1.81732177734375, Accuracy: 80.0%\n",
      "Epoch: 1/1, Step: 3401/5000, Loss: 3.2807412147521973, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 3501/5000, Loss: 4.310170650482178, Accuracy: 40.0%\n",
      "Epoch: 1/1, Step: 3601/5000, Loss: 0.4265597462654114, Accuracy: 90.0%\n",
      "Epoch: 1/1, Step: 3701/5000, Loss: 4.336150169372559, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 3801/5000, Loss: 1.1663099527359009, Accuracy: 70.0%\n",
      "Epoch: 1/1, Step: 3901/5000, Loss: 3.5459282398223877, Accuracy: 40.0%\n",
      "Epoch: 1/1, Step: 4001/5000, Loss: 2.553795337677002, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4101/5000, Loss: 1.8509899377822876, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4201/5000, Loss: 0.9291962385177612, Accuracy: 80.0%\n",
      "Epoch: 1/1, Step: 4301/5000, Loss: 1.6831245422363281, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4401/5000, Loss: 1.0684046745300293, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4501/5000, Loss: 4.544939994812012, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4601/5000, Loss: 3.1949210166931152, Accuracy: 30.0%\n",
      "Epoch: 1/1, Step: 4701/5000, Loss: 4.793157577514648, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4801/5000, Loss: 1.0590440034866333, Accuracy: 60.0%\n",
      "Epoch: 1/1, Step: 4901/5000, Loss: 2.143068313598633, Accuracy: 60.0%\n",
      "Run Time: 1954.289935350418\n"
     ]
    }
   ],
   "source": [
    "# Store time to calculate train time\n",
    "start_time = time.time()\n",
    "\n",
    "# Store loss and accuracy data\n",
    "loss = []\n",
    "accuracy = []\n",
    "\n",
    "# Train the model\n",
    "# Loop for number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop through data in batch sized increments\n",
    "    for batch_idx, (X_train_batch, Y_train_batch) in enumerate(train_loader):\n",
    "        # If trained on all data in epoch, move onto next epoch\n",
    "        if(Y_train_batch.shape[0]<batch_size):\n",
    "            continue\n",
    "\n",
    "        # Forward pass through network\n",
    "        output = model(X_train_batch)                           \n",
    "        # Calculate loss of predictions\n",
    "        curr_loss = criterion(output, Y_train_batch)            \n",
    "        # Store loss\n",
    "        loss.append(curr_loss.item())                           \n",
    "\n",
    "        # Clear last calculation\n",
    "        optimizer.zero_grad()                                   \n",
    "        # Calculate gradient based on loss\n",
    "        curr_loss.backward()                                    \n",
    "        # Update model weights\n",
    "        optimizer.step()                                        \n",
    "\n",
    "        # Extract model predictions\n",
    "        _, predicted = torch.max(output.data, 1) \n",
    "        # Calculate number of correct predictions\n",
    "        correct = (predicted == Y_train_batch).sum().item()     \n",
    "        # Calculate/store accuracy\n",
    "        accuracy.append(correct/Y_train_batch.size(0))          \n",
    "        \n",
    "        # Intermitently print statistics\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: ' + str(epoch+1) + '/' + str(num_epochs) + ', Step: ' \n",
    "                  + str(batch_idx+1) + '/' + str(len(train_loader)) + ', Loss: ' \n",
    "                  + str(curr_loss.item()) + ', Accuracy: ' \n",
    "                  + str(correct/Y_train_batch.size(0)*100) + '%')\n",
    "\n",
    "# Store time to calculate train time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print train time\n",
    "print('Run Time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 27.839999999999996%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# Set model to testing (constant weights)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Store number of correct/total samples in test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Loop through test data\n",
    "    for X_test_batch, Y_test_batch in test_loader:\n",
    "        # Forward pass through network\n",
    "        output = model(X_test_batch)  \n",
    "        \n",
    "        # Extract prediction\n",
    "        _, predicted = torch.max(output.data, 1)    \n",
    "        \n",
    "        # Update total number of sample\n",
    "        total += Y_test_batch.size(0)  \n",
    "        \n",
    "        # Update number of correct predictions\n",
    "        correct += (predicted == Y_test_batch).sum().item()     \n",
    "\n",
    "print('Test Accuracy: ' + str((correct/total) * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
